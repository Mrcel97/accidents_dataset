{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import matplotlib\n",
    "import unidecode\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import chardet\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets_path = \"../data/raw/accidents/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load dataframes data into list of DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_name(df, name):\n",
    "    df.name = name\n",
    "    return df\n",
    "\n",
    "def predict_encoding(file_path, n_lines=10):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            rawdata = b''.join([f.readline() for _ in range(n_lines)])\n",
    "            return chardet.detect(rawdata)['encoding']\n",
    "\n",
    "# Load dataframes with special encoding\n",
    "df_2010 = pd.read_csv(datasets_path + '2010_accidents.csv', encoding=predict_encoding(datasets_path + '2010_accidents.csv'))\n",
    "df_2011 = pd.read_csv(datasets_path + '2011_accidents.csv', encoding=predict_encoding(datasets_path + '2011_accidents.csv'))\n",
    "df_2012 = pd.read_csv(datasets_path + '2012_accidents.csv', encoding=predict_encoding(datasets_path + '2012_accidents.csv'))\n",
    "df_2013 = pd.read_csv(datasets_path + '2012_accidents.csv', encoding=predict_encoding(datasets_path + '2013_accidents.csv'))\n",
    "df_2015 = pd.read_csv(datasets_path + '2015_accidents.csv', encoding=predict_encoding(datasets_path + '2015_accidents.csv'))\n",
    "df_2016 = pd.read_csv(datasets_path + '2016_accidents.csv', encoding=predict_encoding(datasets_path + '2016_accidents.csv'))\n",
    "\n",
    "df_names = ['df_2010', 'df_2011', 'df_2012', 'df_2013','df_2015', 'df_2016']\n",
    "\n",
    "# Concatenate dataframes\n",
    "accidents_df_list = [df_2010, df_2011, df_2012, df_2013, df_2015, df_2016]\n",
    "\n",
    "accidents_df_list = [set_name(df, name) for df, name in zip(accidents_df_list, df_names)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Find wrong/missing data\n",
    "## Step 2.1: Normalize column names\n",
    "    1) Swap space \" \" for underscore \"_\" and remove apostrophe \"'\"\n",
    "    2) Deunicode and lowercase columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>número_dexpedient</th>\n",
       "      <th>codi_districte</th>\n",
       "      <th>nom_districte</th>\n",
       "      <th>codi_barri</th>\n",
       "      <th>nom_barri</th>\n",
       "      <th>codi_carrer</th>\n",
       "      <th>nom_carrer</th>\n",
       "      <th>num_postal_caption</th>\n",
       "      <th>descripció_dia_setmana</th>\n",
       "      <th>dia_setmana</th>\n",
       "      <th>...</th>\n",
       "      <th>dia_de_mes</th>\n",
       "      <th>hora_de_dia</th>\n",
       "      <th>descripció_causa_vianant</th>\n",
       "      <th>desc._tipus_vehicle_implicat</th>\n",
       "      <th>descripció_sexe</th>\n",
       "      <th>descripció_tipus_persona</th>\n",
       "      <th>edat</th>\n",
       "      <th>descripció_victimització</th>\n",
       "      <th>coordenada_utm_(y)</th>\n",
       "      <th>coordenada_utm_(x)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015S005991</td>\n",
       "      <td>-1</td>\n",
       "      <td>Desconegut</td>\n",
       "      <td>-1</td>\n",
       "      <td>Desconegut</td>\n",
       "      <td>-1</td>\n",
       "      <td>Desconegut</td>\n",
       "      <td>Desconegut</td>\n",
       "      <td>Dimarts</td>\n",
       "      <td>Dm</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>No és causa del  vianant</td>\n",
       "      <td>Motocicleta</td>\n",
       "      <td>Home</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>36</td>\n",
       "      <td>Ferit lleu</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  número_dexpedient  codi_districte nom_districte  codi_barri   nom_barri  \\\n",
       "0       2015S005991              -1    Desconegut          -1  Desconegut   \n",
       "\n",
       "   codi_carrer  nom_carrer num_postal_caption descripció_dia_setmana  \\\n",
       "0           -1  Desconegut         Desconegut                Dimarts   \n",
       "\n",
       "  dia_setmana  ... dia_de_mes  hora_de_dia  descripció_causa_vianant  \\\n",
       "0          Dm  ...          4            4  No és causa del  vianant   \n",
       "\n",
       "  desc._tipus_vehicle_implicat  descripció_sexe  descripció_tipus_persona  \\\n",
       "0                  Motocicleta             Home                 Conductor   \n",
       "\n",
       "  edat descripció_victimització coordenada_utm_(y) coordenada_utm_(x)  \n",
       "0   36               Ferit lleu                 -1                 -1  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_headers(df):\n",
    "    df.columns = df.columns.str.replace(' ', '_').str.replace('\\'', '')\n",
    "    df.rename(columns=lambda c: c.lower(), inplace=True)\n",
    "    return df\n",
    "\n",
    "accidents_df = [clean_headers(df) for df in accidents_df_list]\n",
    "accidents_df[4].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.2: Remove unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecessary_cols = [\"descripció_dia_setmana\", \"descripció_torn\", \"long\", \"lat\"]\n",
    "\n",
    "def clean_cols(df):\n",
    "    for col in unnecessary_cols:\n",
    "        if col in df: \n",
    "            del df[col]\n",
    "    return df\n",
    "\n",
    "accidents_df = [clean_cols(df) for df in accidents_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.3: Find inconsistent data among Dataframes rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_col(df, col):\n",
    "    df[col] = df[col].dropna()\n",
    "    return df\n",
    "\n",
    "def delete_multispaces(row):\n",
    "    for index, value in row.items():\n",
    "        if type(value) == str:\n",
    "            value = value.strip()\n",
    "            value = re.sub(r'(?<=[A-Za-z])( +)(?=[A-Za-z])', ' ', value)\n",
    "            value = re.sub(r'(?<=\\d)( +)(?=\\d)?', '', value)\n",
    "            row.at[index] = value\n",
    "    return row\n",
    "\n",
    "for df in accidents_df:\n",
    "    df_name = df.name\n",
    "    null_cols = list(df.columns[df.isna().any()])\n",
    "\n",
    "    for null_col in null_cols:\n",
    "        df = df[(df[null_col].notna()) & (df[null_col].replace(\" \", \"\"))]\n",
    "\n",
    "    if \"num_postal_caption\" in df: \n",
    "        del df[\"num_postal_caption\"]\n",
    "\n",
    "    \n",
    "    df = df.apply(delete_multispaces)\n",
    "    \n",
    "    df.to_csv(df_name + \"_out.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
